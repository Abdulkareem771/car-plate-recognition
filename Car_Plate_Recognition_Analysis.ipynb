{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚗 Car License Plate Recognition System\n",
        "## A Comprehensive Analysis and Implementation Guide\n",
        "\n",
        "---\n",
        "\n",
        "### 📋 Table of Contents\n",
        "1. [Project Overview](#project-overview)\n",
        "2. [System Architecture](#system-architecture)\n",
        "3. [Data Preparation](#data-preparation)\n",
        "4. [Model Training](#model-training)\n",
        "5. [Inference and Testing](#inference-and-testing)\n",
        "6. [Real-time Detection](#real-time-detection)\n",
        "7. [Results and Performance](#results-and-performance)\n",
        "8. [Future Improvements](#future-improvements)\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Project Overview\n",
        "\n",
        "This project implements an **end-to-end car license plate detection and recognition system** using state-of-the-art computer vision techniques. The system is specifically designed for **Yemeni license plates** and leverages YOLOv8 (You Only Look Once) for object detection.\n",
        "\n",
        "### Key Features:\n",
        "- ✅ **Real-time license plate detection** from images and video streams\n",
        "- ✅ **YOLOv8-based object detection** with high accuracy\n",
        "- ✅ **Automated data preprocessing** and annotation conversion\n",
        "- ✅ **Live streaming support** for real-time monitoring\n",
        "- ✅ **Professional-grade implementation** with proper error handling\n",
        "\n",
        "### Technology Stack:\n",
        "- **Deep Learning**: YOLOv8 (Ultralytics)\n",
        "- **Computer Vision**: OpenCV, PIL\n",
        "- **Data Processing**: Pandas, NumPy\n",
        "- **Streaming**: Real-time video processing\n",
        "- **Deployment**: Python with modular architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ System Architecture\n",
        "\n",
        "The car plate recognition system follows a modular architecture designed for scalability and maintainability:\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[Input Images/Video] --> B[Data Preprocessing]\n",
        "    B --> C[YOLOv8 Model Training]\n",
        "    C --> D[Model Validation]\n",
        "    D --> E[Inference Engine]\n",
        "    E --> F[Real-time Detection]\n",
        "    F --> G[Output Results]\n",
        "    \n",
        "    H[Live Stream] --> I[Frame Processing]\n",
        "    I --> E\n",
        "    \n",
        "    J[CSV Annotations] --> K[YOLO Format Conversion]\n",
        "    K --> B\n",
        "```\n",
        "\n",
        "### Core Components:\n",
        "\n",
        "1. **Data Pipeline** (`convert_to_yolo.py`)\n",
        "   - Converts CSV annotations to YOLO format\n",
        "   - Handles multiple datasets (train/validation/test)\n",
        "   - Ensures proper coordinate normalization\n",
        "\n",
        "2. **Model Training** (`main.py`, `yemen car plate number model tran.py`)\n",
        "   - YOLOv8 model initialization and training\n",
        "   - Configurable hyperparameters\n",
        "   - GPU acceleration support\n",
        "\n",
        "3. **Inference Engine** (`model_test.py`, `seperated-plates.py`)\n",
        "   - Batch processing of test images\n",
        "   - Plate cropping and extraction\n",
        "   - Results visualization\n",
        "\n",
        "4. **Real-time Processing** (`recognition-with-live-stream/live-stream.py`)\n",
        "   - Live video stream processing\n",
        "   - Real-time detection and visualization\n",
        "   - Error handling and reconnection logic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ultralytics import YOLO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Display project structure\n",
        "print(\"📁 Project Structure:\")\n",
        "print(\"=\" * 50)\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    level = root.replace(\".\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \" \" * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files) - 5} more files\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Data Preparation\n",
        "\n",
        "The data preparation phase is crucial for training an effective YOLO model. Our system handles two main datasets:\n",
        "\n",
        "### Dataset Information:\n",
        "- **Primary Dataset**: Yemen Car Plate Dataset (v1i.yolov8)\n",
        "- **Secondary Dataset**: Yemen Plate Dataset\n",
        "- **Format**: YOLO format with normalized coordinates\n",
        "- **Classes**: 1 class (License Plate)\n",
        "- **Total Images**: ~200+ images across train/validation/test splits\n",
        "\n",
        "### Data Distribution:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze dataset distribution\n",
        "def analyze_dataset_structure():\n",
        "    \"\"\"Analyze the structure and distribution of our datasets\"\"\"\n",
        "    \n",
        "    datasets = {\n",
        "        \"Yemen Car Plate v1i\": \"src/data/plat number car yemen.v1i.yolov8\",\n",
        "        \"Yemen Plate\": \"src/data/yemen-plate\"\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for name, path in datasets.items():\n",
        "        if os.path.exists(path):\n",
        "            train_images = len([f for f in os.listdir(f\"{path}/train/images\") if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            val_images = len([f for f in os.listdir(f\"{path}/valid/images\") if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            test_images = len([f for f in os.listdir(f\"{path}/test/images\") if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            \n",
        "            results[name] = {\n",
        "                'train': train_images,\n",
        "                'validation': val_images,\n",
        "                'test': test_images,\n",
        "                'total': train_images + val_images + test_images\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze datasets\n",
        "dataset_stats = analyze_dataset_structure()\n",
        "\n",
        "# Create visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Dataset comparison\n",
        "datasets = list(dataset_stats.keys())\n",
        "train_counts = [dataset_stats[ds]['train'] for ds in datasets]\n",
        "val_counts = [dataset_stats[ds]['validation'] for ds in datasets]\n",
        "test_counts = [dataset_stats[ds]['test'] for ds in datasets]\n",
        "\n",
        "x = np.arange(len(datasets))\n",
        "width = 0.25\n",
        "\n",
        "ax1.bar(x - width, train_counts, width, label='Train', alpha=0.8)\n",
        "ax1.bar(x, val_counts, width, label='Validation', alpha=0.8)\n",
        "ax1.bar(x + width, test_counts, width, label='Test', alpha=0.8)\n",
        "\n",
        "ax1.set_xlabel('Dataset')\n",
        "ax1.set_ylabel('Number of Images')\n",
        "ax1.set_title('Dataset Distribution Comparison')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(datasets, rotation=45)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Pie chart for primary dataset\n",
        "primary_dataset = \"Yemen Car Plate v1i\"\n",
        "if primary_dataset in dataset_stats:\n",
        "    sizes = [dataset_stats[primary_dataset]['train'], \n",
        "             dataset_stats[primary_dataset]['validation'], \n",
        "             dataset_stats[primary_dataset]['test']]\n",
        "    labels = ['Train', 'Validation', 'Test']\n",
        "    colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
        "    \n",
        "    ax2.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "    ax2.set_title(f'{primary_dataset} Split Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"📈 Dataset Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "for name, stats in dataset_stats.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Train: {stats['train']} images\")\n",
        "    print(f\"  Validation: {stats['validation']} images\") \n",
        "    print(f\"  Test: {stats['test']} images\")\n",
        "    print(f\"  Total: {stats['total']} images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
