{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Car License Plate Detection and Recognition System\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project implements an automated car license plate detection and recognition system using computer vision and deep learning techniques. The system is designed to detect license plates from vehicle images or video streams, extract the plate region, and recognize the characters for further processing.\n",
        "\n",
        "### Team Members\n",
        "- **Ahmed Al-duais** - \n",
        "- **Abulkareem Thiab** -   \n",
        "- **Ayman Mrwan** - \n",
        "\n",
        "### Project Goals\n",
        "1. Develop an accurate license plate detection system using YOLO\n",
        "2. Implement OCR-based text recognition for Arabic and English characters\n",
        "3. Create user-friendly GUI applications for real-time processing\n",
        "4. Compare different model architectures and select the optimal one\n",
        "\n",
        "### Technology Stack\n",
        "- **Deep Learning**: YOLOv8 (Ultralytics)\n",
        "- **OCR**: EasyOCR\n",
        "- **GUI Framework**: PySide6 (Qt)\n",
        "- **Computer Vision**: OpenCV\n",
        "- **Data Processing**: NumPy, Pandas\n",
        "- **Visualization**: Matplotlib, Seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure matplotlib for better plots\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Analysis and Exploration\n",
        "\n",
        "### Dataset Structure\n",
        "\n",
        "Our project utilizes two main datasets for training and validation:\n",
        "\n",
        "1. **Primary Dataset**: `plat number car yemen.v1i.yolov8`\n",
        "   - Single class: \"private\" \n",
        "   - 80 training images, 16 validation images, 8 test images\n",
        "   - Focus on private vehicle license plates\n",
        "\n",
        "2. **Extended Dataset**: `yemen-plate`\n",
        "   - Three classes: \"city\", \"number\", \"text\"\n",
        "   - 52 training images, 52 validation images, 52 test images\n",
        "   - More detailed annotation for different plate components\n",
        "\n",
        "Let's explore the dataset structure and characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset exploration\n",
        "def explore_dataset(dataset_path, dataset_name):\n",
        "    \"\"\"Explore dataset structure and provide statistics\"\"\"\n",
        "    print(f\"\\n=== {dataset_name} Dataset Analysis ===\")\n",
        "    \n",
        "    # Check if dataset exists\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(f\"Dataset not found at: {dataset_path}\")\n",
        "        return\n",
        "    \n",
        "    # Count images in each split\n",
        "    splits = ['train', 'valid', 'test']\n",
        "    total_images = 0\n",
        "    \n",
        "    for split in splits:\n",
        "        split_path = os.path.join(dataset_path, split, 'images')\n",
        "        if os.path.exists(split_path):\n",
        "            image_count = len([f for f in os.listdir(split_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            print(f\"{split.capitalize()} images: {image_count}\")\n",
        "            total_images += image_count\n",
        "        else:\n",
        "            print(f\"{split.capitalize()} images: 0 (directory not found)\")\n",
        "    \n",
        "    print(f\"Total images: {total_images}\")\n",
        "    \n",
        "    # Check for labels\n",
        "    for split in splits:\n",
        "        label_path = os.path.join(dataset_path, split, 'labels')\n",
        "        if os.path.exists(label_path):\n",
        "            label_count = len([f for f in os.listdir(label_path) if f.endswith('.txt')])\n",
        "            print(f\"{split.capitalize()} labels: {label_count}\")\n",
        "    \n",
        "    # Read data.yaml if exists\n",
        "    yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
        "    if os.path.exists(yaml_path):\n",
        "        print(f\"\\nDataset configuration found: {yaml_path}\")\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            print(f.read())\n",
        "\n",
        "# Explore both datasets\n",
        "datasets = {\n",
        "    \"Primary Dataset\": \"src/data/plat number car yemen.v1i.yolov8\",\n",
        "    \"Extended Dataset\": \"src/data/yemen-plate\"\n",
        "}\n",
        "\n",
        "for name, path in datasets.items():\n",
        "    explore_dataset(path, name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images from the dataset\n",
        "def visualize_sample_images(dataset_path, dataset_name, num_samples=4):\n",
        "    \"\"\"Display sample images from the dataset\"\"\"\n",
        "    print(f\"\\n=== Sample Images from {dataset_name} ===\")\n",
        "    \n",
        "    # Get sample images from training set\n",
        "    train_images_path = os.path.join(dataset_path, 'train', 'images')\n",
        "    if not os.path.exists(train_images_path):\n",
        "        print(f\"Training images not found at: {train_images_path}\")\n",
        "        return\n",
        "    \n",
        "    image_files = [f for f in os.listdir(train_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    if len(image_files) == 0:\n",
        "        print(\"No images found in training directory\")\n",
        "        return\n",
        "    \n",
        "    # Select random samples\n",
        "    import random\n",
        "    sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
        "    \n",
        "    # Create subplot\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for i, filename in enumerate(sample_files):\n",
        "        if i >= 4:\n",
        "            break\n",
        "            \n",
        "        img_path = os.path.join(train_images_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        axes[i].imshow(img_rgb)\n",
        "        axes[i].set_title(f\"Sample {i+1}: {filename[:30]}...\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(sample_files), 4):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize samples from both datasets\n",
        "for name, path in datasets.items():\n",
        "    visualize_sample_images(path, name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Development and Training\n",
        "\n",
        "### YOLO Model Architecture Selection\n",
        "\n",
        "Our project involved testing different YOLO model architectures to find the optimal balance between accuracy and performance:\n",
        "\n",
        "1. **YOLOv8n (Nano)**: Initial attempt with lightweight model\n",
        "   - Fast inference but insufficient accuracy\n",
        "   - Results stored in `runs/detect/detect_nano/`\n",
        "\n",
        "2. **YOLOv8s (Small)**: Final selected model\n",
        "   - Better accuracy while maintaining reasonable speed\n",
        "   - 50 epochs training with comprehensive evaluation\n",
        "   - Results stored in `runs/detect/yolov8n14/`\n",
        "\n",
        "### Training Configuration\n",
        "\n",
        "The final model was trained with the following parameters:\n",
        "- **Model**: YOLOv8s (small)\n",
        "- **Epochs**: 50\n",
        "- **Image Size**: 640x640\n",
        "- **Batch Size**: 9\n",
        "- **Optimizer**: Auto (AdamW)\n",
        "- **Learning Rate**: 0.01 (with cosine annealing)\n",
        "- **Data Augmentation**: Enabled (mosaic, mixup, cutmix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze training results\n",
        "def load_training_results(results_path):\n",
        "    \"\"\"Load and analyze YOLO training results\"\"\"\n",
        "    results_file = os.path.join(results_path, 'results.csv')\n",
        "    \n",
        "    if not os.path.exists(results_file):\n",
        "        print(f\"Results file not found: {results_file}\")\n",
        "        return None\n",
        "    \n",
        "    # Load results\n",
        "    df = pd.read_csv(results_file)\n",
        "    \n",
        "    print(f\"Training completed in {len(df)} epochs\")\n",
        "    print(f\"Total training time: {df['time'].iloc[-1]:.2f} seconds ({df['time'].iloc[-1]/3600:.2f} hours)\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Load training results\n",
        "results_path = \"runs/detect/yolov8n14\"\n",
        "training_results = load_training_results(results_path)\n",
        "\n",
        "if training_results is not None:\n",
        "    print(\"\\n=== Training Results Summary ===\")\n",
        "    print(f\"Final mAP50: {training_results['metrics/mAP50(B)'].iloc[-1]:.4f}\")\n",
        "    print(f\"Final mAP50-95: {training_results['metrics/mAP50-95(B)'].iloc[-1]:.4f}\")\n",
        "    print(f\"Final Precision: {training_results['metrics/precision(B)'].iloc[-1]:.4f}\")\n",
        "    print(f\"Final Recall: {training_results['metrics/recall(B)'].iloc[-1]:.4f}\")\n",
        "    print(f\"Final Box Loss: {training_results['train/box_loss'].iloc[-1]:.4f}\")\n",
        "    print(f\"Final Class Loss: {training_results['train/cls_loss'].iloc[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training metrics\n",
        "def plot_training_metrics(df):\n",
        "    \"\"\"Plot training metrics over epochs\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # Plot 1: Loss curves\n",
        "    axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss', color='blue')\n",
        "    axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss', color='red')\n",
        "    axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss', color='green')\n",
        "    axes[0, 0].set_title('Training Losses')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    # Plot 2: Validation losses\n",
        "    axes[0, 1].plot(df['epoch'], df['val/box_loss'], label='Val Box Loss', color='blue')\n",
        "    axes[0, 1].plot(df['epoch'], df['val/cls_loss'], label='Val Class Loss', color='red')\n",
        "    axes[0, 1].plot(df['epoch'], df['val/dfl_loss'], label='Val DFL Loss', color='green')\n",
        "    axes[0, 1].set_title('Validation Losses')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # Plot 3: Precision and Recall\n",
        "    axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision', color='purple')\n",
        "    axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall', color='orange')\n",
        "    axes[1, 0].set_title('Precision and Recall')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Score')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    # Plot 4: mAP scores\n",
        "    axes[1, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5', color='red')\n",
        "    axes[1, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', color='blue')\n",
        "    axes[1, 1].set_title('Mean Average Precision')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('mAP')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if training_results is not None:\n",
        "    plot_training_metrics(training_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Implementation and Architecture\n",
        "\n",
        "### Core Components\n",
        "\n",
        "Our license plate recognition system consists of three main components:\n",
        "\n",
        "1. **Plate Detector**: YOLO-based object detection for locating license plates\n",
        "2. **Plate Recognizer**: OCR-based text extraction using EasyOCR\n",
        "3. **GUI Application**: PySide6-based user interface for real-time processing\n",
        "\n",
        "### Plate Detection Module\n",
        "\n",
        "The `PlateDetector` class handles the detection of license plates in images:\n",
        "\n",
        "```python\n",
        "class PlateDetector:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "    \n",
        "    def detect(self, image, conf_threshold=0.5):\n",
        "        \"\"\"Detect license plates in an image\"\"\"\n",
        "        results = self.model(image)\n",
        "        detections = []\n",
        "        \n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                conf = float(box.conf[0])\n",
        "                if conf >= conf_threshold:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "                    detections.append({\n",
        "                        'bbox': (x1, y1, x2, y2),\n",
        "                        'confidence': conf,\n",
        "                        'crop': image[y1:y2, x1:x2]\n",
        "                    })\n",
        "        \n",
        "        return detections\n",
        "```\n",
        "\n",
        "### Text Recognition Module\n",
        "\n",
        "The `PlateRecognizer` class handles OCR for Arabic and English text:\n",
        "\n",
        "```python\n",
        "class PlateRecognizer:\n",
        "    def __init__(self, languages=['en', 'ar']):\n",
        "        self.reader = easyocr.Reader(languages)\n",
        "    \n",
        "    def recognize(self, image):\n",
        "        \"\"\"Recognize text from a license plate image\"\"\"\n",
        "        ocr_results = self.reader.readtext(image)\n",
        "        text_detected = \" \".join([res[1] for res in ocr_results])\n",
        "        \n",
        "        # Fix common misread words\n",
        "        if \"خصوصي\" in text_detected or \"نقل\" in text_detected:\n",
        "            text_detected = \"خصوصي نقل اجرة\"\n",
        "            \n",
        "        return text_detected\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the model on sample images\n",
        "def test_model_on_samples():\n",
        "    \"\"\"Test the trained model on sample images\"\"\"\n",
        "    try:\n",
        "        from ultralytics import YOLO\n",
        "        import easyocr\n",
        "        \n",
        "        # Load the trained model\n",
        "        model_path = \"src/models/yolov8s14/weights/best.pt\"\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Model not found at: {model_path}\")\n",
        "            return\n",
        "        \n",
        "        model = YOLO(model_path)\n",
        "        print(\"Model loaded successfully!\")\n",
        "        \n",
        "        # Load OCR\n",
        "        reader = easyocr.Reader(['en', 'ar'])\n",
        "        print(\"OCR reader initialized!\")\n",
        "        \n",
        "        # Test on sample images\n",
        "        test_images_path = \"src/data/plat number car yemen.v1i.yolov8/test/images\"\n",
        "        if os.path.exists(test_images_path):\n",
        "            image_files = [f for f in os.listdir(test_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            \n",
        "            if len(image_files) > 0:\n",
        "                # Test on first image\n",
        "                test_image = os.path.join(test_images_path, image_files[0])\n",
        "                print(f\"\\nTesting on: {image_files[0]}\")\n",
        "                \n",
        "                # Load and process image\n",
        "                img = cv2.imread(test_image)\n",
        "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                \n",
        "                # Detect plates\n",
        "                results = model(img)\n",
        "                \n",
        "                # Process results\n",
        "                detections = []\n",
        "                for r in results:\n",
        "                    for box in r.boxes:\n",
        "                        conf = float(box.conf[0])\n",
        "                        if conf >= 0.5:  # Confidence threshold\n",
        "                            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "                            detections.append({\n",
        "                                'bbox': (x1, y1, x2, y2),\n",
        "                                'confidence': conf,\n",
        "                                'crop': img[y1:y2, x1:x2]\n",
        "                            })\n",
        "                \n",
        "                print(f\"Found {len(detections)} license plates\")\n",
        "                \n",
        "                # Display results\n",
        "                fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "                \n",
        "                # Original image\n",
        "                axes[0].imshow(img_rgb)\n",
        "                axes[0].set_title(\"Original Image\")\n",
        "                axes[0].axis('off')\n",
        "                \n",
        "                # Annotated image\n",
        "                annotated = img_rgb.copy()\n",
        "                for i, det in enumerate(detections):\n",
        "                    x1, y1, x2, y2 = det['bbox']\n",
        "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(annotated, f\"Plate {i+1}: {det['confidence']:.2f}\", \n",
        "                               (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "                \n",
        "                axes[1].imshow(annotated)\n",
        "                axes[1].set_title(\"Detection Results\")\n",
        "                axes[1].axis('off')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                \n",
        "                # Test OCR on detected plates\n",
        "                for i, det in enumerate(detections):\n",
        "                    if det['crop'].size > 0:\n",
        "                        try:\n",
        "                            ocr_results = reader.readtext(det['crop'])\n",
        "                            text_detected = \" \".join([res[1] for res in ocr_results])\n",
        "                            print(f\"Plate {i+1} text: {text_detected}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"OCR failed for plate {i+1}: {e}\")\n",
        "            else:\n",
        "                print(\"No test images found\")\n",
        "        else:\n",
        "            print(\"Test images directory not found\")\n",
        "            \n",
        "    except ImportError as e:\n",
        "        print(f\"Required libraries not available: {e}\")\n",
        "        print(\"Please install ultralytics and easyocr to test the model\")\n",
        "\n",
        "# Test the model\n",
        "test_model_on_samples()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
